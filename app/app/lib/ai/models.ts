import type { AIModel } from '@/types';

export const AI_MODELS: Record<string, AIModel> = {
  // OpenAI - GPT-5.2 Series (December 2025) - Current Frontier Models
  'gpt-5.2': {
    id: 'gpt-5.2',
    name: 'GPT-5.2 Thinking',
    provider: 'openai',
    contextWindow: 512000,
    supportsStreaming: true,
    supportsVision: true,
    supportsImageGen: false,
    supportsThinking: true,
    supportsResearch: true,
    maxTokens: 64000,
  },
  'gpt-5.2-chat-latest': {
    id: 'gpt-5.2-chat-latest',
    name: 'GPT-5.2 Instant',
    provider: 'openai',
    contextWindow: 512000,
    supportsStreaming: true,
    supportsVision: true,
    supportsImageGen: false,
    supportsThinking: true,
    supportsResearch: true,
    maxTokens: 64000,
  },
  'gpt-5.2-pro': {
    id: 'gpt-5.2-pro',
    name: 'GPT-5.2 Pro',
    provider: 'openai',
    contextWindow: 1000000,
    supportsStreaming: true,
    supportsVision: true,
    supportsImageGen: false,
    supportsThinking: true,
    supportsResearch: true,
    maxTokens: 128000,
  },

  // OpenAI - GPT-5.1 Series (November 2025)
  'gpt-5.1': {
    id: 'gpt-5.1-2025-11-13',
    name: 'GPT-5.1',
    provider: 'openai',
    contextWindow: 256000,
    supportsStreaming: true,
    supportsVision: true,
    supportsImageGen: false,
    supportsThinking: true,
    supportsResearch: true,
    maxTokens: 32768,
  },
  'gpt-5.1-chat': {
    id: 'gpt-5.1-chat-2025-11-13',
    name: 'GPT-5.1 Chat',
    provider: 'openai',
    contextWindow: 256000,
    supportsStreaming: true,
    supportsVision: true,
    supportsImageGen: false,
    supportsThinking: true,
    maxTokens: 32768,
  },
  'gpt-5.1-pro': {
    id: 'gpt-5.1-pro-2025-11-19',
    name: 'GPT-5.1 Pro',
    provider: 'openai',
    contextWindow: 512000,
    supportsStreaming: true,
    supportsVision: true,
    supportsImageGen: false,
    supportsThinking: true,
    supportsResearch: true,
    maxTokens: 64000,
  },
  'gpt-5.1-nano': {
    id: 'gpt-5.1-nano-2025-11-13',
    name: 'GPT-5.1 Nano',
    provider: 'openai',
    contextWindow: 64000,
    supportsStreaming: true,
    supportsVision: true,
    supportsImageGen: false,
    supportsThinking: false,
    maxTokens: 8192,
  },
  'gpt-5.1-mini': {
    id: 'gpt-5.1-mini-2025-11-13',
    name: 'GPT-5.1 Mini',
    provider: 'openai',
    contextWindow: 128000,
    supportsStreaming: true,
    supportsVision: true,
    supportsImageGen: false,
    supportsThinking: true,
    maxTokens: 16384,
  },
  'gpt-5.1-codex': {
    id: 'gpt-5.1-codex-2025-11-13',
    name: 'GPT-5.1 Codex',
    provider: 'openai',
    contextWindow: 256000,
    supportsStreaming: true,
    supportsVision: true,
    supportsImageGen: false,
    supportsThinking: true,
    maxTokens: 32768,
  },
  'gpt-5.1-codex-mini': {
    id: 'gpt-5.1-codex-mini-2025-11-13',
    name: 'GPT-5.1 Codex Mini',
    provider: 'openai',
    contextWindow: 128000,
    supportsStreaming: true,
    supportsVision: true,
    supportsImageGen: false,
    supportsThinking: true,
    maxTokens: 16384,
  },
  'gpt-5.1-codex-max': {
    id: 'gpt-5.1-codex-max-2025-11-19',
    name: 'GPT-5.1 Codex Max',
    provider: 'openai',
    contextWindow: 512000,
    supportsStreaming: true,
    supportsVision: true,
    supportsImageGen: false,
    supportsThinking: true,
    maxTokens: 64000,
  },

  // OpenAI - Image & Video Generation
  'dall-e-3': {
    id: 'dall-e-3',
    name: 'DALL-E 3',
    provider: 'openai',
    contextWindow: 0,
    supportsStreaming: false,
    supportsVision: false,
    supportsImageGen: true,
    maxTokens: 0,
  },
  'image-1': {
    id: 'image-1',
    name: 'Image-1',
    provider: 'openai',
    contextWindow: 0,
    supportsStreaming: false,
    supportsVision: false,
    supportsImageGen: true,
    maxTokens: 0,
  },
  'sora-2': {
    id: 'sora-2',
    name: 'Sora 2',
    provider: 'openai',
    contextWindow: 0,
    supportsStreaming: false,
    supportsVision: true,
    supportsImageGen: false,
    supportsVideoGen: true,
    maxTokens: 0,
  },
  'sora-2-pro': {
    id: 'sora-2-pro',
    name: 'Sora 2 Pro',
    provider: 'openai',
    contextWindow: 0,
    supportsStreaming: false,
    supportsVision: true,
    supportsImageGen: false,
    supportsVideoGen: true,
    maxTokens: 0,
  },

  // Anthropic - Claude 4.5 Series (All with Thinking & Research)
  'claude-4.5-opus': {
    id: 'claude-4-5-opus-20250514',
    name: 'Claude 4.5 Opus',
    provider: 'anthropic',
    contextWindow: 500000,
    supportsStreaming: true,
    supportsVision: true,
    supportsImageGen: false,
    supportsThinking: true,
    supportsResearch: true,
    maxTokens: 16384,
  },
  'claude-4.5-sonnet': {
    id: 'claude-4-5-sonnet-20250514',
    name: 'Claude 4.5 Sonnet',
    provider: 'anthropic',
    contextWindow: 500000,
    supportsStreaming: true,
    supportsVision: true,
    supportsImageGen: false,
    supportsThinking: true,
    supportsResearch: true,
    maxTokens: 16384,
  },
  'claude-4.5-haiku': {
    id: 'claude-4-5-haiku-20250514',
    name: 'Claude 4.5 Haiku',
    provider: 'anthropic',
    contextWindow: 200000,
    supportsStreaming: true,
    supportsVision: true,
    supportsImageGen: false,
    supportsThinking: true,
    supportsResearch: true,
    maxTokens: 8192,
  },

  // Google - Gemini Series
  'gemini-3-pro': {
    id: 'gemini-3.0-pro-latest',
    name: 'Gemini 3 Pro',
    provider: 'google',
    contextWindow: 2000000,
    supportsStreaming: true,
    supportsVision: true,
    supportsImageGen: false,
    supportsThinking: true,
    supportsResearch: true,
    maxTokens: 16384,
  },
  'gemini-2.5-pro': {
    id: 'gemini-2.5-pro-latest',
    name: 'Gemini 2.5 Pro',
    provider: 'google',
    contextWindow: 2000000,
    supportsStreaming: true,
    supportsVision: true,
    supportsImageGen: false,
    supportsThinking: true,
    supportsResearch: true,
    maxTokens: 16384,
  },
  'gemini-2.5-flash': {
    id: 'gemini-2.5-flash-latest',
    name: 'Gemini 2.5 Flash',
    provider: 'google',
    contextWindow: 1000000,
    supportsStreaming: true,
    supportsVision: true,
    supportsImageGen: false,
    supportsThinking: false,
    supportsResearch: true,
    maxTokens: 8192,
  },

  // xAI - Grok Series
  'grok-4.1': {
    id: 'grok-4.1',
    name: 'Grok 4.1',
    provider: 'xai',
    contextWindow: 256000,
    supportsStreaming: true,
    supportsVision: true,
    supportsImageGen: false,
    supportsThinking: true,
    supportsResearch: true,
    maxTokens: 16384,
  },
  'grok-4': {
    id: 'grok-4',
    name: 'Grok 4',
    provider: 'xai',
    contextWindow: 256000,
    supportsStreaming: true,
    supportsVision: true,
    supportsImageGen: false,
    supportsThinking: true,
    supportsResearch: true,
    maxTokens: 16384,
  },

  // Mistral
  'mistral-large': {
    id: 'mistral-large-latest',
    name: 'Mistral Large',
    provider: 'mistral',
    contextWindow: 32000,
    supportsStreaming: true,
    supportsVision: false,
    supportsImageGen: false,
    maxTokens: 4096,
  },

  // Perplexity
  'sonar-large': {
    id: 'llama-3.1-sonar-large-128k-online',
    name: 'Sonar Large',
    provider: 'perplexity',
    contextWindow: 128000,
    supportsStreaming: true,
    supportsVision: false,
    supportsImageGen: false,
    supportsResearch: true,
    maxTokens: 4096,
  },

  // Meta (via Together AI)
  'llama-3.1-70b': {
    id: 'meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo',
    name: 'LLaMA 3.1 70B',
    provider: 'meta',
    contextWindow: 131072,
    supportsStreaming: true,
    supportsVision: false,
    supportsImageGen: false,
    maxTokens: 4096,
  },

  // Local (Ollama)
  'llama-3.1-local': {
    id: 'llama3.1',
    name: 'LLaMA 3.1 (Local)',
    provider: 'local',
    contextWindow: 8192,
    supportsStreaming: true,
    supportsVision: false,
    supportsImageGen: false,
    maxTokens: 2048,
  },
};

export function getModel(modelId: string): AIModel | undefined {
  return AI_MODELS[modelId];
}

export function getModelsByProvider(provider: string): AIModel[] {
  return Object.values(AI_MODELS).filter((model) => model.provider === provider);
}

export function getAllModels(): AIModel[] {
  return Object.values(AI_MODELS);
}
